{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Yes it is possible to identify individuals either directly or indirectly from the dataset. If we have another dataset that have the comment style of different indivduals as the feature vector and the name of the individuals as the label, we can train a model that classifies comments. We can then run this dataset through the model and predict which individual made the given comment. <br /><br />\n",
    "ii. The dataset could be used to train a model that classifies the emotion of a comment based on the style of the comment. It can also be used to train a model that classifies the emotion of a comment based on the time the comment is made. <br /><br />\n",
    "iii. The dataset shouuld not be used to train a model that predicts the time the coment is made based on the coment style. It also shouldn't be feed into other models that would potentially violate the privacy of commenters, e.x their names, birthdates, gender, or other personal information.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. ['best', 'book', 'ever', 'it', 's', 'great'] <br /><br />\n",
    "b. d = 8468 <br /><br />\n",
    "c. Average number of non-zero features per comment in the training data: 12.136932305055698<br /><br />\n",
    "    The word appearing in the most number of comments: little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Hyperparameter Selection for a Linear_kernel SVM\n",
    "\n",
    "a. <br />\n",
    "By maintaining class proportions across folds, we are minimizing the deviation of folds away from the original training data. This way, the model each fold produces better reflects what a true model would be like if we train on the entire training data. <br /><br />\n",
    "\n",
    "b. \n",
    "| Performance Measures \t| C    \t| Performance        \t|\n",
    "|----------------------\t|------\t|--------------------\t|\n",
    "| Accuracy             \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "| F1-Score             \t| 1.0  \t| 0.9202149609972474 \t|\n",
    "| AUROC                \t| 0.1  \t| 0.9723006785314479 \t|\n",
    "| Precision            \t| 0.01 \t| 0.9980048758644708 \t|\n",
    "| Sensitivity          \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "| Specificity          \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "\n",
    "Generally, the performance improves and reaches a peak and then decays again as we move from smaller to greater C values. I would use accuracy (C = 1.0) as the performance metrics to optimize for C because it is the most strict one: the set of labels predicted for a sample must exactly match the corresponding set of labels. This ensures that the model we train is rigorous.<br /><br />\n",
    "\n",
    "c.\n",
    "| Performance Measures \t| Performance        \t|\n",
    "|----------------------\t|--------------------\t|\n",
    "| Accuracy             \t| 0.9253370953370954 \t|\n",
    "| F1-Score             \t| 0.9239432326275698 \t|\n",
    "| AUROC                \t| 0.9725875877253337 \t|\n",
    "| Precision            \t| 0.941512254275592  \t|\n",
    "| Sensitivity          \t| 0.9253370953370954 \t|\n",
    "| Specificity          \t| 0.9253370953370954 \t|\n",
    "\n",
    "d.<br />\n",
    "![](Norm-l2_penalty.png)\n",
    "\n",
    "e. <br />\n",
    "![](Coefficient_vs_word.png)\n",
    "\n",
    "f. <br />\n",
    "Gladly you didn't miss the disappointing data points. Congrats and thanks! Thank you again for your time and sorry for any inconvenience.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Linear-Kernel SVM with L1 Penalty and Sqaured Hinge Loss\n",
    "\n",
    "a. <br />\n",
    "C value: 1.0 <br />\n",
    "The mean CV AUROC score: 0.9682126750588289 <br />\n",
    "AUROC test score: 0.974850924269529 <br />\n",
    "\n",
    "b.<br />\n",
    "![](Norm-l1_penalty.png)\n",
    "\n",
    "c.<br />\n",
    "We observe that the norms for l2 penalty is much larger than that of l1, meaning that l1 penalty produces a much sparser theta for all C values. The gradient of l1 is constant to each element, meaning that all coefficients are reduced by the same amount so many unimportant features eventually has 0 as their weights to reduce the penalty. If we take the gradient of the minimization expression using l2, we find that it is linear to theta itself. This means that the model can balance the weights of different features and have a more complex parameter vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Hyperparameter Selection for a Quadatic_Kernel SVM\n",
    "\n",
    "a.\n",
    "| Tuning Scheme \t| C                 \t| r                  \t| AUROC              \t|\n",
    "|---------------\t|-------------------\t|--------------------\t|--------------------\t|\n",
    "| Grid Search   \t| 1.0               \t| 100.0              \t| 0.9724901418747572 \t|\n",
    "| Random Search \t| 41.87830236855281 \t| 1.9600598203396193 \t| 0.9720746270361655 \t|\n",
    "\n",
    "b. <br />\n",
    "Generally, if we fix one of C and r and let the other variable vary, the performance curve with respect to the variable always goes up, peaks, and then decays. As C increases, we will see such curves with absolutely better performance but earlier peaks with respect to r. As r increases, we will also see such curves with absolutely better performance but ealier peaks with respect to C. The pros of grid search would be that we can specify the combination of parameter we want by hard-coding. The cons is that if we have multiple parameters, this process becomes very time-consuming. The pros of random search is that we can quickly generate a lot of combinations using a random distribution function; however, we have limited control over the values of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Learning Non-linear Classifiers with a Linear-Kernel SVM\n",
    "\n",
    "a. <br />\n",
    "![](4.4a.png)\n",
    "\n",
    "b. <br />\n",
    "Pros: Despite being efficient, using the kernel method may mean loss of information from the original feature mapping. For example, 4x^2 can be 2x*2x or (-2x)*(-2x).<br /><br />\n",
    "Cons: Feature mapping to such a high-dimensional space is extremely inefficient and can take a lot of resources to run<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Asymmetric Cost Functions and Class Imbalance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff736c5c8260fecefcd908694e246a75f13a31c6b9c152fae9a522ac29de4dde"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
