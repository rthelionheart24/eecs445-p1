{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Yes it is possible to identify individuals either directly or indirectly from the dataset. If we have another dataset that have the comment style of different indivduals as the feature vector and the name of the individuals as the label, we can train a model that classifies comments. We can then run this dataset through the model and predict which individual made the given comment. <br /><br />\n",
    "ii. The dataset could be used to train a model that classifies the emotion of a comment based on the style of the comment. It can also be used to train a model that classifies the emotion of a comment based on the time the comment is made. <br /><br />\n",
    "iii. The dataset shouuld not be used to train a model that predicts the time the coment is made based on the coment style. It also shouldn't be feed into other models that would potentially violate the privacy of commenters, e.x their names, birthdates, gender, or other personal information.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. ['best', 'book', 'ever', 'it', 's', 'great'] <br /><br />\n",
    "b. d = 8468 <br /><br />\n",
    "c. Average number of non-zero features per comment in the training data: 12.136932305055698<br /><br />\n",
    "    The word appearing in the most number of comments: little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Hyperparameter Selection for a Linear_kernel SVM\n",
    "\n",
    "a. <br />\n",
    "By maintaining class proportions across folds, we are minimizing the deviation of folds away from the original training data. This way, the model each fold produces better reflects what a true model would be like if we train on the entire training data. <br /><br />\n",
    "\n",
    "b. \n",
    "| Performance Measures \t| C    \t| Performance        \t|\n",
    "|----------------------\t|------\t|--------------------\t|\n",
    "| Accuracy             \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "| F1-Score             \t| 1.0  \t| 0.9202149609972474 \t|\n",
    "| AUROC                \t| 0.1  \t| 0.9723006785314479 \t|\n",
    "| Precision            \t| 0.01 \t| 0.9980048758644708 \t|\n",
    "| Sensitivity          \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "| Specificity          \t| 1.0  \t| 0.9210263820957463 \t|\n",
    "\n",
    "Generally, the performance improves and reaches a peak and then decays again as we move from smaller to greater C values. I would use accuracy (C = 1.0) as the performance metrics to optimize for C because it is the most strict one: the set of labels predicted for a sample must exactly match the corresponding set of labels. This ensures that the model we train is rigorous.<br /><br />\n",
    "\n",
    "c.\n",
    "| Performance Measures \t| Performance        \t|\n",
    "|----------------------\t|--------------------\t|\n",
    "| Accuracy             \t| 0.9253370953370954 \t|\n",
    "| F1-Score             \t| 0.9239432326275698 \t|\n",
    "| AUROC                \t| 0.9725875877253337 \t|\n",
    "| Precision            \t| 0.941512254275592  \t|\n",
    "| Sensitivity          \t| 0.9253370953370954 \t|\n",
    "| Specificity          \t| 0.9253370953370954 \t|\n",
    "\n",
    "d.<br /><br />\n",
    "![](Norm-l2_penalty.png)\n",
    "\n",
    "e. <br /><br />\n",
    "![](Coefficient_vs_word.png)\n",
    "\n",
    "f. <br /><br />\n",
    "Gladly you didn't miss the disappointing data points. Congrats and thanks! Thank you again for your time and sorry for any inconvenience.<br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Linear-Kernel SVM with L1 Penalty and Sqaured Hinge Loss\n",
    "\n",
    "a. <br /><br />\n",
    "C value: 1.0 <br /><br />\n",
    "The mean CV AUROC score: 0.9682126750588289 <br /><br />\n",
    "AUROC test score: 0.974850924269529 <br /><br />\n",
    "\n",
    "b.<br /><br />\n",
    "![](Norm-l1_penalty.png)\n",
    "\n",
    "c.<br /><br />\n",
    "The l0-norm of a model regularized by l2-norm decreases as C increases. The l0-norm of a model regularized by l1-norm increases as C increases. We observe that the norms for l2 penalty is much larger than that of l1, meaning that l1 penalty produces a sparser theta.  If we take the gradient of the minimization expression using l2, we find that the first term becomes the l2-norm of theta itself. As C increases, we obtain theta with greater l2-norm , so the model has to omit the weights of many features(turning them into 0 in the parameter vector) . However, for l1, taking the derivative results in a constant first term. This means that the model does\n",
    "\n",
    "# Not done yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Hyperparameter Selection for a Quadatic_Kernel SVM\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff736c5c8260fecefcd908694e246a75f13a31c6b9c152fae9a522ac29de4dde"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
